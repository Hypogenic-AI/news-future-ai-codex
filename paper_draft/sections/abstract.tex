\section*{Abstract}
\label{sec:abstract}
We study whether prediction-market probabilities can ground large language model (LLM) narratives about future events. Existing forecasting benchmarks focus on short answers, but real-world consumers and decision-makers often need full news-style narratives that convey uncertainty. We compare a baseline prompt with no market signal to a market-conditioned prompt that explicitly provides the market probability. Using 30 unresolved binary markets from \manifold, we generate paired ``news from the future'' articles with \gptfourone and evaluate them using an LLM judge for plausibility, coherence, and alignment with the market prior. Market-conditioned prompting improves plausibility from 4.367 to 5.000 and alignment from 3.133 to 5.000 while reducing probability error from 0.282 to 0.000 (paired $t$-tests, $p<10^{-5}$, large effect sizes). Coherence remains at ceiling for both conditions, and length and hedging rates show no significant change. These results suggest that prediction-market priors are a lightweight, effective mechanism for producing uncertainty-aware future-news narratives and motivate broader validation with human evaluation and historical market snapshots.
